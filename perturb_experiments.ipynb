{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import gates_models as gm\n",
    "import pickle\n",
    "import utils as ut\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_suffix = 'r5'\n",
    "subset = 'all'\n",
    "path = f'models_{round_suffix}'\n",
    "main_path = os.path.join(path, 'round6-train-dataset') if round_suffix == 'r6' else os.path.join(path, 'round5-train-dataset')\n",
    "models_path = os.path.join(main_path, 'models')\n",
    "metadata_file = 'METADATA.csv'    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "df = pandas.read_csv(os.path.join(main_path, metadata_file))\n",
    "torch.backends.cudnn.enabled=False\n",
    "use_amp = True if torch.cuda.is_available() else False # attempt to use mixed precision to accelerate embedding conversion process\n",
    "# ut.write_embeddings_on_file(df, main_path, models_path, round_suffix=round_suffix, input_type='clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_types = ['l1']\n",
    "threshold = (0.95, 0.7) # (1, 0.7)\n",
    "gg = 'all' # 'per_sample'\n",
    "\n",
    "for reg_type in reg_types:\n",
    "    print(f'Reg Type: {reg_type}')\n",
    "    cdrp_hgates_all_params = {'threshold':threshold, 'start':0.05, 'iter':50, 'lr':0.1, 'eps':1e-2, 'gate_type':'hidden', 'reg_type':reg_type, 'gate_granularity':gg, 'subset':subset}\n",
    "    hgates_all, hgates_all_accs, hgates_all_gammas, class_indices, model_labels, trigger_targets = gm.apply_cdrp_on_all_models(df, main_path, models_path, cdrp_hgates_all_params, round_suffix, use_amp, device)\n",
    "\n",
    "    cdrp_igates_all_params = {'threshold':threshold, 'start':0.05, 'iter':50, 'lr':0.1, 'eps':1e-2, 'gate_type':'input', 'reg_type':reg_type, 'gate_granularity':gg, 'subset':subset}\n",
    "    igates_all, igates_all_accs, igates_all_gammas, _, _, _ = gm.apply_cdrp_on_all_models(df, main_path, models_path, cdrp_igates_all_params, round_suffix, use_amp, device)\n",
    "\n",
    "    with open(f'{round_suffix}_{gg}_{reg_type}_data.pickle', 'wb') as handle:\n",
    "        pickle.dump((hgates_all, hgates_all_accs, hgates_all_gammas, igates_all, igates_all_accs, igates_all_gammas, class_indices, model_labels, trigger_targets), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = 'all'\n",
    "\n",
    "with open(f'{round_suffix}_{gg}_l1_data.pickle', 'rb') as handle:\n",
    "    all_l1_data =  pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48, 6)\n"
     ]
    }
   ],
   "source": [
    "model_labels = all_l1_data[7]\n",
    "hconfs_l1_data = np.array([[all_l1_data[1][idx][0][1], all_l1_data[1][idx][1][1], all_l1_data[1][idx][2][1]] for idx in range(len(model_labels))])\n",
    "iconfs_l1_data = np.array([[all_l1_data[4][idx][0][1], all_l1_data[4][idx][1][1], all_l1_data[4][idx][2][1]] for idx in range(len(model_labels))])\n",
    "data = np.hstack((hconfs_l1_data, iconfs_l1_data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data, model_labels, stratify=model_labels)\n",
    "# scoring = make_scorer(accuracy_score)\n",
    "# parameters = {'learning_rate': [0.15,0.1,0.05,0.01,0.005,0.001],  'n_estimators': [100,250,500,750,1000,1250,1500], 'max_depth': [3,5,7]}\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), parameters, scoring=scoring, refit=True, cv=2, n_jobs=-1).fit(X_train, y_train)\n",
    "# print(f'Acc: {clf.score(X_test, y_test):.2f} - AUC: {roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]):.2f}')\n",
    "\n",
    "clf = LogisticRegression(penalty='l2', C=100).fit(data, model_labels)\n",
    "with open('clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc: 0.73 - AUC: 0.80\n"
     ]
    }
   ],
   "source": [
    "with open('clf.pickle', 'rb') as handle:\n",
    "    clf = pickle.load(handle)\n",
    "\n",
    "print(f'Acc: {clf.score(data, model_labels):.2f} - AUC: {roc_auc_score(model_labels, clf.predict_proba(data)[:, 1]):.2f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bitpytorchcondad9770c3b7f1448618a8c506bdbfa1806",
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}