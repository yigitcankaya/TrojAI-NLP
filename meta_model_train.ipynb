{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import gates_models as gm\n",
    "import pickle\n",
    "import utils as ut\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_suffix = 'r5'\n",
    "subset = 'all'\n",
    "path = f'models_{round_suffix}'\n",
    "main_path = os.path.join(path, 'round6-train-dataset') if round_suffix == 'r6' else os.path.join(path, 'round5-train-dataset')\n",
    "models_path = os.path.join(main_path, 'models')\n",
    "metadata_file = 'METADATA.csv'    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "df = pandas.read_csv(os.path.join(main_path, metadata_file))\n",
    "df = df[0:11]##delete it in normal case\n",
    "torch.backends.cudnn.enabled=False\n",
    "use_amp = False # True if torch.cuda.is_available() else False # attempt to use mixed precision to accelerate embedding conversion process\n",
    "#ut.write_embeddings_on_file(df, main_path, models_path, round_suffix=round_suffix, use_amp=use_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(f'data_{round_suffix}', 'embeddings.pickle'), 'rb') as handle:\n",
    "    data =  pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is okey\n",
      "data is okey\n"
     ]
    }
   ],
   "source": [
    "data['embeddings']#we are using only the first embedding so there are 40 samples for each model\n",
    "data[\"logits\"]#models prediction for 40 samples\n",
    "data['instance_labels']#labels of 40 samples for each model\n",
    "data['model_labels']#shows whether the model is poisoned or not.\n",
    "print(\"data is okey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg Type: sparse\n",
      "Collecting CDRPs for 11 models with sparse regularization...\n",
      "Idx: 0 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Reg Type: sparse\n",
      "Collecting CDRPs for 11 models with sparse regularization...\n",
      "Idx: 0 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 1 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 1 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 2 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 2 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 3 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 3 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 4 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 4 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 5 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 5 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 6 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 6 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 7 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 7 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 8 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 8 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 9 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 9 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 10 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Idx: 10 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: LstmLinear - Gate Type: hidden - Gate Granularity: all\n",
      "Collecting CDRPs for 11 models with sparse regularization...\n",
      "Idx: 0 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Collecting CDRPs for 11 models with sparse regularization...\n",
      "Idx: 0 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 1 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 1 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 2 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 2 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 3 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 3 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 4 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 4 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 5 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 5 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 6 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 6 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 7 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 7 - Poisoned: False - Embedding: GPT-2-gpt2.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 8 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 8 - Poisoned: False - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: GruLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 9 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 9 - Poisoned: True - Embedding: DistilBERT-distilbert-base-uncased.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 10 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n",
      "Idx: 10 - Poisoned: True - Embedding: GPT-2-gpt2.pt - Arch: LstmLinear - Gate Type: input - Gate Granularity: all\n"
     ]
    }
   ],
   "source": [
    "##extracting features for all models for both hidden gates and input gates state \n",
    "reg_types = ['sparse']\n",
    "threshold = (0.95, 0.7); gg = 'all'\n",
    "# threshold = (1, 0.7); gg = 'per_sample'\n",
    "\n",
    "\n",
    "for reg_type in reg_types:\n",
    "    print(f'Reg Type: {reg_type}')\n",
    "    cdrp_hgates_all_params = {'threshold':threshold, 'start':0.05, 'iter':50, 'lr':0.1, 'eps':1e-2, 'gate_type':'hidden', 'reg_type':reg_type, 'gate_granularity':gg, 'subset':subset}\n",
    "    hgates_all, hgates_all_accs, hgates_all_gammas, class_indices, model_labels, trigger_targets = gm.apply_cdrp_on_all_models(df, main_path, models_path, cdrp_hgates_all_params, round_suffix, use_amp, device)\n",
    "\n",
    "    cdrp_igates_all_params = {'threshold':threshold, 'start':0.05, 'iter':50, 'lr':0.1, 'eps':1e-2, 'gate_type':'input', 'reg_type':reg_type, 'gate_granularity':gg, 'subset':subset}\n",
    "    igates_all, igates_all_accs, igates_all_gammas, _, _, _ = gm.apply_cdrp_on_all_models(df, main_path, models_path, cdrp_igates_all_params, round_suffix, use_amp, device)\n",
    "\n",
    "    with open(os.path.join(f'data_{round_suffix}', f'{gg}_{reg_type}_data.pickle'), 'wb') as handle:\n",
    "        pickle.dump((hgates_all, hgates_all_accs, hgates_all_gammas, igates_all, igates_all_accs, igates_all_gammas, class_indices, model_labels, trigger_targets), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgates_all[8][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the features\n",
    "gg = 'all'\n",
    "round_suffix = 'r5'\n",
    "\n",
    "with open(os.path.join(f'data_{round_suffix}', f'{gg}_l1_data.pickle'), 'rb') as handle:\n",
    "    all_l1_r5 =  pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(f'data_{round_suffix}', f'{gg}_l2_data.pickle'), 'rb') as handle:\n",
    "    all_l2_r5 =  pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(f'data_{round_suffix}', f'{gg}_sparse_data.pickle'), 'rb') as handle:\n",
    "    all_sp_r5 =  pickle.load(handle)\n",
    "\n",
    "round_suffix = 'r6'\n",
    "\n",
    "with open(os.path.join(f'data_{round_suffix}', f'{gg}_l1_data.pickle'), 'rb') as handle:\n",
    "    all_l1_r6 =  pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(f'data_{round_suffix}', f'{gg}_l2_data.pickle'), 'rb') as handle:\n",
    "    all_l2_r6 =  pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(f'data_{round_suffix}', f'{gg}_sparse_data.pickle'), 'rb') as handle:\n",
    "    all_sp_r6 =  pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_l1_r5[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract features from row data. There are 1656 models\n",
    "d = lambda x: np.linalg.norm(x - 1, ord=1)\n",
    "dd = lambda x, y: np.linalg.norm(x - y, ord=1)\n",
    "s = lambda x: len(np.where(x == 0)[0])/len(x)\n",
    "##maybe adding variance might be a good option\n",
    "\n",
    "model_labels_r5 = all_l1_r5[7]\n",
    "\n",
    "#using norm of c0, c1 and c1-c0 gates\n",
    "#we are not using the information for extracting\n",
    "hconfs_l1_r5 = np.array([[all_l1_r5[1][idx][0][1], all_l1_r5[1][idx][1][1], all_l1_r5[1][idx][2][1]] for idx in range(len(model_labels_r5))])\n",
    "iconfs_l1_r5 = np.array([[all_l1_r5[4][idx][0][1], all_l1_r5[4][idx][1][1], all_l1_r5[4][idx][2][1]] for idx in range(len(model_labels_r5))])\n",
    "hgammas_l1_r5 = np.array([[all_l1_r5[2][idx][0], all_l1_r5[2][idx][1]] for idx in range(len(model_labels_r5))])\n",
    "igammas_l1_r5 = np.array([[all_l1_r5[5][idx][0], all_l1_r5[5][idx][1]] for idx in range(len(model_labels_r5))])\n",
    "hgates_l1_r5 = np.array([[d(all_l1_r5[0][idx][0]), d(all_l1_r5[0][idx][1]), dd(all_l1_r5[0][idx][0], all_l1_r5[0][idx][1])] for idx in range(len(model_labels_r5))])\n",
    "igates_l1_r5 = np.array([[d(all_l1_r5[3][idx][0]), d(all_l1_r5[3][idx][1]), dd(all_l1_r5[3][idx][0], all_l1_r5[3][idx][1])] for idx in range(len(model_labels_r5))])\n",
    "\n",
    "# l1_r5 = np.hstack((hconfs_l1_r5, iconfs_l1_r5, hgammas_l1_r5, igammas_l1_r5, hgates_l1_r5, igates_l1_r5))\n",
    "l1_r5 = np.hstack((iconfs_l1_r5, igammas_l1_r5, igates_l1_r5))\n",
    "\n",
    "hconfs_l2_r5 = np.array([[all_l2_r5[1][idx][0][1], all_l2_r5[1][idx][1][1], all_l2_r5[1][idx][2][1]] for idx in range(len(model_labels_r5))])\n",
    "iconfs_l2_r5 = np.array([[all_l2_r5[4][idx][0][1], all_l2_r5[4][idx][1][1], all_l2_r5[4][idx][2][1]] for idx in range(len(model_labels_r5))])\n",
    "hgammas_l2_r5 = np.array([[all_l2_r5[2][idx][0], all_l2_r5[2][idx][1]] for idx in range(len(model_labels_r5))])\n",
    "igammas_l2_r5 = np.array([[all_l2_r5[5][idx][0], all_l2_r5[5][idx][1]] for idx in range(len(model_labels_r5))])\n",
    "hgates_l2_r5 = np.array([[d(all_l2_r5[0][idx][0]), d(all_l2_r5[0][idx][1]), dd(all_l2_r5[0][idx][0], all_l2_r5[0][idx][1])] for idx in range(len(model_labels_r5))])\n",
    "igates_l2_r5 = np.array([[d(all_l2_r5[3][idx][0]), d(all_l2_r5[3][idx][1]), dd(all_l2_r5[3][idx][0], all_l2_r5[3][idx][1])] for idx in range(len(model_labels_r5))])\n",
    "\n",
    "# l2_r5 = np.hstack((hconfs_l2_r5, iconfs_l2_r5, hgammas_l2_r5, igammas_l2_r5, hgates_l2_r5, igates_l2_r5))\n",
    "l2_r5 = np.hstack((iconfs_l2_r5, igammas_l2_r5, igates_l2_r5))\n",
    "\n",
    "\n",
    "hconfs_sp_r5 = np.array([[all_sp_r5[1][idx][0][1], all_sp_r5[1][idx][1][1], all_sp_r5[1][idx][2][1]] for idx in range(len(model_labels_r5))])\n",
    "iconfs_sp_r5 = np.array([[all_sp_r5[4][idx][0][1], all_sp_r5[4][idx][1][1], all_sp_r5[4][idx][2][1]] for idx in range(len(model_labels_r5))])\n",
    "hgammas_sp_r5 = np.array([[all_sp_r5[2][idx][0], all_sp_r5[2][idx][1], all_sp_r5[2][idx][2]] for idx in range(len(model_labels_r5))])\n",
    "igammas_sp_r5 = np.array([[all_sp_r5[5][idx][0], all_sp_r5[5][idx][1], all_sp_r5[5][idx][2]] for idx in range(len(model_labels_r5))])\n",
    "hgates_sp_r5 = np.array([[s(all_sp_r5[0][idx][0]), s(all_sp_r5[0][idx][1]), s(all_sp_r5[0][idx][2])] for idx in range(len(model_labels_r5))])\n",
    "igates_sp_r5 = np.array([[s(all_sp_r5[3][idx][0]), s(all_sp_r5[3][idx][1]), s(all_sp_r5[3][idx][2])] for idx in range(len(model_labels_r5))])\n",
    "\n",
    "# sp_r5 = np.hstack((hconfs_sp_r5, iconfs_sp_r5, hgammas_sp_r5, igammas_sp_r5, hgates_sp_r5, igates_sp_r5))\n",
    "sp_r5 = np.hstack((iconfs_sp_r5, igammas_sp_r5, igates_sp_r5))\n",
    "\n",
    "data_r5 = np.hstack((l1_r5, l2_r5, sp_r5))\n",
    "print(data_r5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels_r6 = all_l1_r6[7]\n",
    "\n",
    "hconfs_l1_r6 = np.array([[all_l1_r6[1][idx][0][1], all_l1_r6[1][idx][1][1], all_l1_r6[1][idx][2][1]] for idx in range(len(model_labels_r6))])\n",
    "iconfs_l1_r6 = np.array([[all_l1_r6[4][idx][0][1], all_l1_r6[4][idx][1][1], all_l1_r6[4][idx][2][1]] for idx in range(len(model_labels_r6))])\n",
    "hgammas_l1_r6 = np.array([[all_l1_r6[2][idx][0], all_l1_r6[2][idx][1]] for idx in range(len(model_labels_r6))])\n",
    "igammas_l1_r6 = np.array([[all_l1_r6[5][idx][0], all_l1_r6[5][idx][1]] for idx in range(len(model_labels_r6))])\n",
    "hgates_l1_r6 = np.array([[d(all_l1_r6[0][idx][0]), d(all_l1_r6[0][idx][1]), dd(all_l1_r6[0][idx][0], all_l1_r6[0][idx][1])] for idx in range(len(model_labels_r6))])\n",
    "igates_l1_r6 = np.array([[d(all_l1_r6[3][idx][0]), d(all_l1_r6[3][idx][1]), dd(all_l1_r6[3][idx][0], all_l1_r6[3][idx][1])] for idx in range(len(model_labels_r6))])\n",
    "\n",
    "#l1_r6 = np.hstack((hconfs_l1_r6, iconfs_l1_r6, hgammas_l1_r6, igammas_l1_r6, hgates_l1_r6, igates_l1_r6))\n",
    "l1_r6 = np.hstack((iconfs_l1_r6, igammas_l1_r6, igates_l1_r6))\n",
    "\n",
    "\n",
    "hconfs_l2_r6 = np.array([[all_l2_r6[1][idx][0][1], all_l2_r6[1][idx][1][1], all_l2_r6[1][idx][2][1]] for idx in range(len(model_labels_r6))])\n",
    "iconfs_l2_r6 = np.array([[all_l2_r6[4][idx][0][1], all_l2_r6[4][idx][1][1], all_l2_r6[4][idx][2][1]] for idx in range(len(model_labels_r6))])\n",
    "hgammas_l2_r6 = np.array([[all_l2_r6[2][idx][0], all_l2_r6[2][idx][1]] for idx in range(len(model_labels_r6))])\n",
    "igammas_l2_r6 = np.array([[all_l2_r6[5][idx][0], all_l2_r6[5][idx][1]] for idx in range(len(model_labels_r6))])\n",
    "hgates_l2_r6 = np.array([[d(all_l2_r6[0][idx][0]), d(all_l2_r6[0][idx][1]), dd(all_l2_r6[0][idx][0], all_l2_r6[0][idx][1])] for idx in range(len(model_labels_r6))])\n",
    "igates_l2_r6 = np.array([[d(all_l2_r6[3][idx][0]), d(all_l2_r6[3][idx][1]), dd(all_l2_r6[3][idx][0], all_l2_r6[3][idx][1])] for idx in range(len(model_labels_r6))])\n",
    "\n",
    "# l2_r6 = np.hstack((hconfs_l2_r6, iconfs_l2_r6, hgammas_l2_r6, igammas_l2_r6, hgates_l2_r6, igates_l2_r6))\n",
    "l2_r6 = np.hstack((iconfs_l2_r6, igammas_l2_r6, igates_l2_r6))\n",
    "\n",
    "\n",
    "hconfs_sp_r6 = np.array([[all_sp_r6[1][idx][0][1], all_sp_r6[1][idx][1][1], all_sp_r6[1][idx][2][1]] for idx in range(len(model_labels_r6))])\n",
    "iconfs_sp_r6 = np.array([[all_sp_r6[4][idx][0][1], all_sp_r6[4][idx][1][1], all_sp_r6[4][idx][2][1]] for idx in range(len(model_labels_r6))])\n",
    "hgammas_sp_r6 = np.array([[all_sp_r6[2][idx][0], all_sp_r6[2][idx][1], all_sp_r6[2][idx][2]] for idx in range(len(model_labels_r6))])\n",
    "igammas_sp_r6 = np.array([[all_sp_r6[5][idx][0], all_sp_r6[5][idx][1], all_sp_r6[5][idx][2]] for idx in range(len(model_labels_r6))])\n",
    "hgates_sp_r6 = np.array([[s(all_sp_r6[0][idx][0]), s(all_sp_r6[0][idx][1]), s(all_sp_r6[0][idx][2])] for idx in range(len(model_labels_r6))])\n",
    "igates_sp_r6 = np.array([[s(all_sp_r6[3][idx][0]), s(all_sp_r6[3][idx][1]), s(all_sp_r6[3][idx][2])] for idx in range(len(model_labels_r6))])\n",
    "\n",
    "# sp_r6 = np.hstack((hconfs_sp_r6, iconfs_sp_r6, hgammas_sp_r6, igammas_sp_r6, hgates_sp_r6, igates_sp_r6))\n",
    "sp_r6 = np.hstack((iconfs_sp_r6, igammas_sp_r6, igates_sp_r6))\n",
    "\n",
    "data_r6 = np.hstack((l1_r6, l2_r6, sp_r6))\n",
    "print(data_r6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spilit data and train a meta learner \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_r5, model_labels_r5, stratify=model_labels_r5, random_state=0)\n",
    "\n",
    "# scoring = make_scorer(accuracy_score)\n",
    "# parameters = {'learning_rate': [0.15,0.1,0.05,0.01,0.005,0.001],  'n_estimators': [100,250,500,750,1000,1250,1500], 'max_depth': [3,5,7]}\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), parameters, scoring=scoring, refit=True, cv=2, n_jobs=-1).fit(X_train, y_train)\n",
    "# print(f'Acc: {clf.score(X_test, y_test):.2f} - AUC: {roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]):.2f}')\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate=0.005, max_depth=3, n_estimators=1000).fit(X_train, y_train)\n",
    "print(f'Acc: {clf.score(X_test, y_test):.2f} - AUC: {roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]):.2f}')\n",
    "\n",
    "# clf = LogisticRegression(penalty='l2', C=10).fit(data, model_labels)\n",
    "\n",
    "# save the model\n",
    "with open('clf.pickle', 'wb') as handle:\n",
    "    pickle.dump(clf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# load the model\n",
    "# with open('clf.pickle', 'rb') as handle:\n",
    "#     clf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Acc: {clf.score(data_r6, model_labels_r6):.2f} - AUC: {roc_auc_score(model_labels_r6, clf.predict_proba(data_r6)[:, 1]):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(data_r6) == model_labels_r6\n",
    "\n",
    "for idx, _ in enumerate(df['model_name']):\n",
    "    params = ut.read_model(df, idx, main_path, models_path)\n",
    "    print(f'Idx: {idx} - Poisoned: {params[2]} - Embedding: {os.path.basename(params[6])} - Arch: {params[1]} Pred Correct: {preds[idx]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(data_r6)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
